{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from torch import nn \n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import signal as sig\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from torch.utils import data\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataloader import LandmarkDataset, SequenceDataset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import normalized_mutual_info_score, confusion_matrix, accuracy_score\n",
    "import VaDE_autoencoder\n",
    "from VaDE_autoencoder import SimpleAutoencoder, VaDE, ClusteringEvaluationCallback\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find landmark files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory of data\n",
    "data_root = Path(\"/home/orel/Storage/Data/K6/\")\n",
    "landmark_files = []\n",
    "for subdir in os.listdir(data_root):\n",
    "    for file in os.listdir(data_root/subdir/'Down'):\n",
    "        if re.match(r\"00\\d*DeepCut_resnet50_Down2May25shuffle1_1030000\\.h5\", file):\n",
    "            lfile = data_root/subdir/'Down'/file\n",
    "            landmark_files.append(lfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the autoencoder\n",
    "\n",
    "create and train autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VaDE_autoencoder\n",
    "from VaDE_autoencoder import SimpleAutoencoder, VaDE\n",
    "%pdb on\n",
    "seqlen = 30\n",
    "model = VaDE(landmark_files, n_neurons=[2*12*seqlen, 512, 512, 30], lr=2e-3, seqlen=seqlen, k=30, batch_norm=True)\n",
    "\n",
    "logger = pl.loggers.WandbLogger(\"landmarks VaDE\")\n",
    "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=10, callbacks=[ClusteringEvaluationCallback()],\n",
    "                     log_every_n_steps=10, max_epochs=50, logger=logger)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "all_dl = data.DataLoader(model.all_ds, batch_size=1024, shuffle=False, num_workers=8)\n",
    "labels, encs = model.cluster_data(dl=all_dl)\n",
    "VaDE_autoencoder.entropy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributions as D\n",
    "def cluster_data(model, dl=None):\n",
    "    if not dl:\n",
    "        dl = model.val_dataloader()\n",
    "    model.eval()\n",
    "    sigma_c = torch.exp(model.logvar_c / 2)\n",
    "    vade_gmm = D.MixtureSameFamily(D.Categorical(logits=model.mixture_logits), D.Normal(model.mu_c, sigma_c))\n",
    "    labels = []\n",
    "    X_encoded = []\n",
    "    with torch.no_grad():\n",
    "        for bx in dl:\n",
    "            x_encoded = model.latent_dist(model.encoder(bx.cuda())).loc\n",
    "            X_encoded.append(x_encoded)\n",
    "            log_p_z_given_c = vade_gmm.component_distribution.log_prob(x_encoded.unsqueeze(2)).sum(dim=1)\n",
    "            labels.append((log_p_z_given_c + vade_gmm.mixture_distribution.logits).softmax(dim=-1).argmax(dim=-1))\n",
    "\n",
    "    labels = torch.cat(labels).cpu().numpy()\n",
    "    X_encoded = torch.cat(X_encoded).cpu().numpy()\n",
    "    return labels, X_encoded\n",
    "\n",
    "dl1 = data.DataLoader(model.all_ds, batch_size=8, shuffle=False, num_workers=8)\n",
    "dl2 = data.DataLoader(model.all_ds, batch_size=1024, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "l1, encs1 = cluster_data(model, dl1)\n",
    "l2, encs2 = cluster_data(model, dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(labels).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('models/vade_03_12')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), model_dir / 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(labels).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = 30\n",
    "\n",
    "model = VaDE(landmark_files, n_neurons=[2*12*seqlen, 512, 512, 30], lr=2e-3, seqlen=seqlen, k=30, batch_norm=True, pretrain=False)\n",
    "model.prepare_data()\n",
    "model.load_state_dict(torch.load('models/vade_11_24/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mixture_logits.softmax(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the original and reconstructed data, each plot for a different feature / coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_plot(x, y, z=None):\n",
    "    x = x.reshape(seqlen, 24)\n",
    "    y = y.reshape(seqlen, 24)\n",
    "    if z is not None:\n",
    "        z = z.reshape(seqlen, 24)\n",
    "    fig, axes = plt.subplots(ncols=4, nrows=6, figsize=(18, 18))\n",
    "    for i in range(6):\n",
    "        for j in range(4):\n",
    "            idx = 4*i + j\n",
    "            axes[i][j].plot(x[:,idx], label='orig')\n",
    "            axes[i][j].plot(y[:,idx], label='recon')\n",
    "            if z is not None:\n",
    "                axes[i][j].plot(z[:,idx], label='train_recon')\n",
    "            axes[i][j].set_title(f\"{idx}\")\n",
    "            axes[i][j].set_ylim(-3, 3)\n",
    "    plt.legend()\n",
    " \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    bx = next(iter(model.train_dataloader()))\n",
    "    out = model(bx.cuda()).loc\n",
    "    model.train()\n",
    "    out_train = model(bx.cuda()).loc\n",
    "_idx = 31\n",
    "compare_plot(bx[_idx].cpu().numpy(), out[_idx].cpu().numpy(), out_train[_idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the landmark coordinates from all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark_ds = LandmarkDataset(landmark_files[0])\n",
    "coords = model.coords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the dataset from all the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, n_coords, _ = model.coords[0].shape\n",
    "all_data = [crds.reshape(-1, n_coords*2) for crds in model.coords]\n",
    "data_lengths = [d.shape[0] - model.seqlen for d in all_data]\n",
    "video_change_idxs = np.cumsum(data_lengths)[:-1]\n",
    "# all_data = [SequenceDataset(d, seqlen=model.seqlen, diff=False, step=1) for d in all_data]\n",
    "# all_data = ConcatDataset(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels, new_X_encoded = model.cluster_data(DataLoader(all_data, batch_size=1024, num_workers=8, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering the data and splitting into segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "model.cuda()\n",
    "labels, X_encoded = model.cluster_data(DataLoader(model.all_ds, batch_size=1024, num_workers=8))\n",
    "'''\n",
    "split the sequence of labels and returns the sequence of segments of the form:\n",
    "      [(label0, segment_start0, segment_length0), ...]\n",
    "for example:\n",
    "44422222227777  ->  [(4, 0, 3), (2, 7), (7, 4)]\n",
    "'''\n",
    "def split_labels(labels):\n",
    "    split_at = np.where(np.diff(labels) != 0)[0] + 1\n",
    "    sequence = [[seg[0], split_at[i-1]*4 + model.seqlen*2, len(seg)*4] \\\n",
    "                for i, seg in enumerate(np.split(labels, indices_or_sections=split_at))]\n",
    "    sequence[0][1] = model.seqlen*2\n",
    "    return sequence\n",
    "\n",
    "labels_dict = dict(zip(landmark_files, \n",
    "                        np.split(labels, indices_or_sections=video_change_idxs)))\n",
    "\n",
    "data_dict = dict(zip(landmark_files,\n",
    "                    np.split(all_data, indices_or_sections=video_change_idxs)))\n",
    "\n",
    "segment_dict = dict(zip(landmark_files, \n",
    "                        map(split_labels, np.split(labels, indices_or_sections=video_change_idxs))))\n",
    "\n",
    "X_encoded_dict = dict(zip(landmark_files,\n",
    "                         np.split(X_encoded, indices_or_sections=video_change_idxs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaDE_autoencoder.entropy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "# model_dir = Path('models/vade_11_24/')\n",
    "\n",
    "np.save(model_dir / 'labels', labels)\n",
    "\n",
    "with open(model_dir / 'labels_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_dict, file)\n",
    "    \n",
    "with open(model_dir / 'data_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(data_dict, file)\n",
    "    \n",
    "with open(model_dir / 'segments_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(segment_dict, file)\n",
    "    \n",
    "with open(model_dir / 'x_encoded_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(X_encoded_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE plot of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idxs = np.random.choice(X_encoded.shape[0], size=10000, replace=False)\n",
    "X_sample = X_encoded[sample_idxs]\n",
    "sample_labels = labels[sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30)\n",
    "X_2d = tsne.fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "sample_labels = labels[sample_idxs]\n",
    "clusters = {int(i): X_2d[np.where(sample_labels==i)[0]] for i in range(30)}\n",
    "plt.figure(figsize=(10, 10))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "for idx, cluster in clusters.items():\n",
    "    # print(cluster)\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], label=idx, s=1, color=cluster_colors[idx])\n",
    "    plt.legend(bbox_to_anchor=(1., 1.), prop={'size': 12}, markerscale=3)\n",
    "    plt.savefig('plots/tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "sample_labels = labels[sample_idxs]\n",
    "clusters = {int(i): X_2d[np.where(sample_labels==i)[0]] for i in range(30)}\n",
    "plt.figure(figsize=(10, 10))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "for idx, cluster in clusters.items():\n",
    "    # print(cluster)\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], label=idx, s=1, color=cluster_colors[idx])\n",
    "    plt.legend(bbox_to_anchor=(1., 1.), prop={'size': 12}, markerscale=3)\n",
    "    plt.savefig('plots/tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "sample_labels = labels[sample_idxs]\n",
    "clusters = {int(i): X_2d[np.where(sample_labels==i)[0]] for i in range(30)}\n",
    "plt.figure(figsize=(10, 10))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "for idx, cluster in clusters.items():\n",
    "    # print(cluster)\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], label=idx, s=1, color=cluster_colors[idx])\n",
    "    plt.legend(bbox_to_anchor=(1., 1.), prop={'size': 12}, markerscale=3)\n",
    "    plt.savefig('plots/tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "sample_labels = labels[sample_idxs]\n",
    "clusters = {int(i): X_2d[np.where(sample_labels==i)[0]] for i in range(30)}\n",
    "plt.figure(figsize=(10, 10))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "for idx, cluster in clusters.items():\n",
    "    # print(cluster)\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], label=idx, s=1, color=cluster_colors[idx])\n",
    "    plt.legend(bbox_to_anchor=(1., 1.), prop={'size': 12}, markerscale=3)\n",
    "    plt.savefig('plots/tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "sample_labels = labels[sample_idxs]\n",
    "clusters = {int(i): X_2d[np.where(sample_labels==i)[0]] for i in range(30)}\n",
    "plt.figure(figsize=(10, 10))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "for idx, cluster in clusters.items():\n",
    "    # print(cluster)\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], label=idx, s=1, color=cluster_colors[idx])\n",
    "    plt.legend(bbox_to_anchor=(1., 1.), prop={'size': 12}, markerscale=3)\n",
    "    plt.savefig('plots/tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = model.landmark_datasets[0].body_parts\n",
    "bodyparts_dict = dict(zip(body_parts, range(len(body_parts))))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "coords = model.coords\n",
    "def plot_segments(axis, vid_file_idx, start_idx, end_idx, bparts):\n",
    "    bparts_idxs = [bodyparts_dict[bp] for bp in bparts]\n",
    "    plot_coords = coords[vid_file_idx][start_idx + model.seqlen//2: end_idx + model.seqlen//2, bparts_idxs]\n",
    "    duration = (end_idx - start_idx) * (1000 / 60)\n",
    "    for i, body_part in enumerate(bparts):\n",
    "        axis.plot(plot_coords[:,i,0], label=f\"{body_part}_x\")\n",
    "        axis.plot(plot_coords[:,i,1], label=f\"{body_part}_y\")\n",
    "    ymin, ymax = axis.get_ybound()\n",
    "    lbls = labels_dict[landmark_files[vid_file_idx]][start_idx: end_idx]\n",
    "#     label_dict = dict(zip(sorted(list(set(lbls))), range(len(set(lbls)))))\n",
    "    segment_edges = np.where(np.diff(lbls) != 0)[0]\n",
    "    segment_edges = np.append(0, segment_edges)\n",
    "    segment_edges = np.append(segment_edges, end_idx - start_idx - 1)\n",
    "    segment_labels = lbls[segment_edges]\n",
    "    axis.margins(0, 0)\n",
    "    axis.vlines(segment_edges, ymin=ymin, ymax=ymax, color='black', linestyle='dashed')\n",
    "    for i in range(1, len(segment_edges)):\n",
    "        cluster_color = cluster_colors[lbls[segment_edges[i]]]\n",
    "        axis.fill_betweenx([ymin, ymax], segment_edges[i-1], segment_edges[i], color=cluster_color, alpha=0.5)\n",
    "    color_patches = [mpatches.Patch(color=cluster_colors[i], label=f'cluster {i}', alpha=0.5) for i in set(lbls)]\n",
    "    cluster_color_legend = axis.legend(handles=color_patches, bbox_to_anchor=(1.0, 0.0), loc='lower left', title='clusters')\n",
    "    ax = plt.gca().add_artist(cluster_color_legend)\n",
    "    handles, labels = axis.get_legend_handles_labels()\n",
    "    axis.legend(handles, labels, bbox_to_anchor=(1.0, 1), title=\"body parts\")\n",
    "    axis.set_title(\"landmark coordinates timeseries\")\n",
    "    axis.set_xticks(np.arange(0, end_idx - start_idx, step=30))\n",
    "    axis.set_xticklabels(np.arange(0, duration/1000, step=0.5))\n",
    "    axis.set_xlabel(\"time [seconds]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))\n",
    "# ax = plt.subplot().axes\n",
    "# %pdb on\n",
    "# plot_segments(ax, 6, 8000, 10000, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot().axes\n",
    "%pdb on\n",
    "plot_segments(ax, 6, 8000, 10000, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bodyparts_dict = dict(zip(landmark_ds.body_parts, range(len(landmark_ds.body_parts))))\n",
    "\n",
    "def plot_segments(axis, vid_file_idx, start_idx, end_idx, bparts):\n",
    "    bparts_idxs = [bodyparts_dict[bp] for bp in bparts]\n",
    "    plot_coords = coords[vid_file_idx][start_idx + model.seqlen//2: end_idx + model.seqlen//2, bparts_idxs]\n",
    "    duration = (end_idx - start_idx) * (1000 / 60)\n",
    "    for i, body_part in enumerate(bparts):\n",
    "        axis.plot(plot_coords[:,i,0], label=f\"{body_part}_x\")\n",
    "        axis.plot(plot_coords[:,i,1], label=f\"{body_part}_y\")\n",
    "    ymin, ymax = axis.get_ybound()\n",
    "    lbls = labels_dict[landmark_files[vid_file_idx]][start_idx: end_idx]\n",
    "#     label_dict = dict(zip(sorted(list(set(lbls))), range(len(set(lbls)))))\n",
    "    segment_edges = np.where(np.diff(lbls) != 0)[0]\n",
    "    segment_edges = np.append(0, segment_edges)\n",
    "    segment_edges = np.append(segment_edges, end_idx - start_idx - 1)\n",
    "    segment_labels = lbls[segment_edges]\n",
    "    axis.margins(0, 0)\n",
    "    axis.vlines(segment_edges, ymin=ymin, ymax=ymax, color='black', linestyle='dashed')\n",
    "    for i in range(1, len(segment_edges)):\n",
    "        cluster_color = cluster_colors[lbls[segment_edges[i]]]\n",
    "        axis.fill_betweenx([ymin, ymax], segment_edges[i-1], segment_edges[i], color=cluster_color, alpha=0.5)\n",
    "    color_patches = [mpatches.Patch(color=cluster_colors[i], label=f'cluster {i}', alpha=0.5) for i in set(lbls)]\n",
    "    cluster_color_legend = axis.legend(handles=color_patches, bbox_to_anchor=(1.0, 0.0), loc='lower left', title='clusters')\n",
    "    ax = plt.gca().add_artist(cluster_color_legend)\n",
    "    handles, labels = axis.get_legend_handles_labels()\n",
    "    axis.legend(handles, labels, bbox_to_anchor=(1.0, 1), title=\"body parts\")\n",
    "    axis.set_title(\"landmark coordinates timeseries\")\n",
    "    axis.set_xticks(np.arange(0, end_idx - start_idx, step=30))\n",
    "    axis.set_xticklabels(np.arange(0, duration/1000, step=0.5))\n",
    "    axis.set_xlabel(\"time [seconds]\")\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot().axes\n",
    "%pdb on\n",
    "plot_segments(ax, 6, 800, 1000, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords1.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some plots to show the cluster at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bodyparts_dict = dict(zip(landmark_datasets[0].body_parts, range(len(landmark_datasets[0]))))\n",
    "\n",
    "def plot_segments(axis, vid_file_idx, start_idx, end_idx, bparts):\n",
    "    bparts_idxs = [bodyparts_dict[bp] for bp in bparts]\n",
    "    plot_coords = coords[vid_file_idx][start_idx + model.seqlen//2: end_idx + model.seqlen//2, bparts_idxs]\n",
    "    duration = (end_idx - start_idx) * (1000 / 60)\n",
    "    for i, body_part in enumerate(bparts):\n",
    "        axis.plot(plot_coords[:,i,0], label=f\"{body_part}_x\")\n",
    "        axis.plot(plot_coords[:,i,1], label=f\"{body_part}_y\")\n",
    "    ymin, ymax = axis.get_ybound()\n",
    "    lbls = labels_dict[landmark_files[vid_file_idx]][start_idx: end_idx]\n",
    "#     label_dict = dict(zip(sorted(list(set(lbls))), range(len(set(lbls)))))\n",
    "    segment_edges = np.where(np.diff(lbls) != 0)[0]\n",
    "    segment_edges = np.append(0, segment_edges)\n",
    "    segment_edges = np.append(segment_edges, end_idx - start_idx - 1)\n",
    "    segment_labels = lbls[segment_edges]\n",
    "    axis.margins(0, 0)\n",
    "    axis.vlines(segment_edges, ymin=ymin, ymax=ymax, color='black', linestyle='dashed')\n",
    "    for i in range(1, len(segment_edges)):\n",
    "        cluster_color = cluster_colors[lbls[segment_edges[i]]]\n",
    "        axis.fill_betweenx([ymin, ymax], segment_edges[i-1], segment_edges[i], color=cluster_color, alpha=0.5)\n",
    "    color_patches = [mpatches.Patch(color=cluster_colors[i], label=f'cluster {i}', alpha=0.5) for i in set(lbls)]\n",
    "    cluster_color_legend = axis.legend(handles=color_patches, bbox_to_anchor=(1.0, 0.0), loc='lower left', title='clusters')\n",
    "    ax = plt.gca().add_artist(cluster_color_legend)\n",
    "    handles, labels = axis.get_legend_handles_labels()\n",
    "    axis.legend(handles, labels, bbox_to_anchor=(1.0, 1), title=\"body parts\")\n",
    "    axis.set_title(\"landmark coordinates timeseries\")\n",
    "    axis.set_xticks(np.arange(0, end_idx - start_idx, step=30))\n",
    "    axis.set_xticklabels(np.arange(0, duration/1000, step=0.5))\n",
    "    axis.set_xlabel(\"time [seconds]\")\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot().axes\n",
    "%pdb on\n",
    "plot_segments(ax, 6, 800, 1000, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot()\n",
    "plot_segments(ax, 6, 0, 200, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot()\n",
    "plot_segments(ax, 6, 0, 200, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = labels_dict[landmark_files[6]]\n",
    "plt.plot(lbls[11800:16000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = labels_dict[landmark_files[6]]\n",
    "plt.plot(lbls[800:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some histogram plots of lengths of some of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "segments = split_labels(labels)\n",
    "segment_lengths = defaultdict(list)\n",
    "for seg in segments:\n",
    "    if seg[2] < 200:\n",
    "        segment_lengths[seg[0]].append(seg[2]/(4*60))\n",
    "    \n",
    "clusters_to_plot = [3, 13, 18, 19]\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(clusters_to_plot), figsize=(8, 12), sharex=True)\n",
    "for i, cl in enumerate(clusters_to_plot):\n",
    "    axes[i].hist(segment_lengths[cl], bins=20, density=True)\n",
    "    axes[i].set_xlim(0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save examples from cluster as frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import importlib\n",
    "import clip_videos\n",
    "from collections import defaultdict\n",
    "importlib.reload(clip_videos)\n",
    "\n",
    "def read_clip_as_frames(cap: cv.VideoCapture, start_idx, end_idx, df, fps=10):\n",
    "    frame_gen = clip_videos.extract_labeled_cut_frames(cap, start_idx, end_idx, df)\n",
    "    write_every = int(cap.get(cv.CAP_PROP_FPS) / fps)\n",
    "    frames = []\n",
    "    for i, frame in enumerate(frame_gen):\n",
    "        if i % write_every == 0:\n",
    "            frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "# landmarks_file = landmark_files[6]\n",
    "# df = landmark_datasets[6].df\n",
    "# video_file = str(landmarks_file.parent / re.sub(r'DeepCut.*\\.h5', '.MP4', landmarks_file.name))\n",
    "# vid_cap = cv.VideoCapture(video_file)\n",
    "# vid_cap.open(video_file)\n",
    "# frames = read_clip_as_frames(vid_cap, 0, 200, df)\n",
    "# frames = read_clip_as_frames(vid_cap, 1000, 1200, df)\n",
    "# frames = read_clip_as_frames(vid_cap, 300, 500, df)\n",
    "# vid_cap.release()\n",
    "# ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(np.concatenate(frames, axis=1))\n",
    "img.save('img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clips_as_frames(landmarks_file, cluster_segments, save_dir, min_seg_len=10, fps=20, n_samples=15):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    video_file = re.sub(r'DeepCut.*\\.h5', '.MP4', landmarks_file.name)\n",
    "    video_file = str(landmarks_file.parent / video_file)\n",
    "    assert os.path.exists(video_file)\n",
    "    vid_cap = cv.VideoCapture(video_file)\n",
    "    vid_cap.open(video_file)\n",
    "    cluster_frames = defaultdict(list)\n",
    "    for seg in cluster_segments:\n",
    "        if seg[2] >= min_seg_len:\n",
    "            cluster_frames[seg[0]].append((seg[1], seg[2]))\n",
    "    cluster_frames = {k: v for k, v in cluster_frames.items() if len(v) >= 15}\n",
    "    cluster_samples = {c: random.choices(cl, k=n_samples) for c, cl in cluster_frames.items()}\n",
    "    df = LandmarkDataset(landmarks_file).df\n",
    "    for cl_id,  cluster in cluster_samples.items():\n",
    "        print(cl_id)\n",
    "        if not os.path.exists(save_dir / f'{cl_id}'):\n",
    "            os.makedirs(save_dir / f'{cl_id}', exist_ok=True)\n",
    "        mid_frames = [c[0] for c in cluster]\n",
    "        n_frames = [c[1] for c in cluster]\n",
    "        n_frames = int(min(60, np.mean(n_frames) + np.std(n_frames)))\n",
    "        for i, mid_frame in enumerate(mid_frames):\n",
    "            start_idx, end_idx = mid_frame - n_frames//2, mid_frame + n_frames//2\n",
    "            frames = read_clip_as_frames(vid_cap, start_idx, end_idx, df=df, fps=fps)\n",
    "            img = Image.fromarray(np.concatenate(frames, axis=1))\n",
    "            img.save(save_dir / f'{cl_id}' / f\"{i}.jpg\")\n",
    "    vid_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "landmarks_file = landmark_files[6]\n",
    "df = landmark_datasets[6].df\n",
    "cluster_subset = [6, 15, 22, 7, 2, 12, 25]\n",
    "segments = [seg for seg in segment_dict[landmarks_file] if seg[0] in cluster_subset]\n",
    "save_dir = Path(\"clusters/frames/oct28_2/\")\n",
    "save_clips_as_frames(landmarks_file, segment_dict[landmarks_file], save_dir, n_samples=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving clips of clusters from the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import importlib\n",
    "import random\n",
    "import clip_videos\n",
    "from collections import defaultdict\n",
    "importlib.reload(clip_videos)\n",
    "\n",
    "# save clips for each cluster from a single video\n",
    "def save_clips(landmarks_file, cluster_segments, save_dir, min_seg_len=10):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    video_file = re.sub(r'DeepCut.*\\.h5', '.MP4', landmarks_file.name)\n",
    "    video_file = landmarks_file.parent / video_file\n",
    "    assert os.path.exists(video_file)\n",
    "    cluster_frames = defaultdict(list)\n",
    "    for seg in cluster_segments:\n",
    "        if seg[2] >= min_seg_len:\n",
    "            cluster_frames[seg[0]].append((seg[1] + seg[2]//2, seg[2]//2))\n",
    "    cluster_frames = {k: v for k, v in cluster_frames.items() if len(v) >= 15}\n",
    "    cluster_samples = {c: random.choices(cl, k=15) for c, cl in cluster_frames.items()}\n",
    "    df = LandmarkDataset(landmarks_file).df\n",
    "    for cl_id,  cluster in cluster_samples.items():\n",
    "        mid_frames = [c[0] for c in cluster]\n",
    "        n_frames = [c[1] for c in cluster]\n",
    "        n_frames = int(min(60, np.mean(n_frames) + np.std(n_frames)))\n",
    "        clip_videos.save_collage_with_labels_short(str(video_file), df, mid_frames, n_frames_around=n_frames,\n",
    "                                             save_file=f'{save_dir}/cluster_{cl_id}.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save clips from all videos, from each video in a seoperate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lfile, segments in segment_dict.items():\n",
    "    save_dir = f'clusters/sept15/{lfile.name[:4]}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        save_clips(lfile, segments, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not really important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "split_at = np.where(np.diff(labels) != 0)[0] + 1\n",
    "sequence = [[s[0], split_at[i-1], len(s)] for i, s in enumerate(np.split(labels, indices_or_sections=split_at))]\n",
    "sequence[0][1] = 0\n",
    "seg_lengths = defaultdict(list)\n",
    "for seg in sequence:\n",
    "    seg_lengths[seg[0]].append(seg[2])\n",
    "\n",
    "sequence = [seq for seq in sequence if seq[2] > 5]\n",
    "\n",
    "cluster_frames = defaultdict(list)\n",
    "for seq in sequence:\n",
    "    cluster_frames[seq[0]].append((seq[1]*4 + seq[2]*2, seq[2]*2))\n",
    "\n",
    "cluster_frames = {c:cl for c, cl in cluster_frames.items() if len(cl)>25}\n",
    "# len(cluster_frames)\n",
    "cluster_samples = {c: random.choices(cl, k=15) for c, cl in cluster_frames.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import importlib\n",
    "import clip_videos\n",
    "importlib.reload(clip_videos)\n",
    "\n",
    "video_file = data_root/'2020-03-23'/'Down'/'0008DeepCut_resnet50_Down2May25shuffle1_1030000_labeled.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl_id,  cluster in cluster_samples.items():\n",
    "    n_frames = [c[1] for c in cluster]\n",
    "    print(cl_id, np.mean(n_frames), np.std(n_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = LandmarkDataset(landmarks_file).df\n",
    "for cl_id,  cluster in cluster_samples.items():\n",
    "    mid_frames = [c[0] for c in cluster]\n",
    "    n_frames = [c[1] for c in cluster]\n",
    "    n_frames = int(min(60, np.mean(n_frames) + np.std(n_frames)))\n",
    "    print(mid_frames)\n",
    "    clip_videos.save_collage_with_labels_short(str(video_file), df, mid_frames, n_frames_around=n_frames,\n",
    "                                         save_file=f'clusters/example_1/cluster_{cl_id}.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls clusters/example_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = [seq[0] for seq in sequence]\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def count_ngrams(sequence, max_n=10):\n",
    "    N = len(sequence)\n",
    "    counter = defaultdict(int)\n",
    "    for k in range(1, max_n):\n",
    "        for i in range(N-k):\n",
    "            counter[tuple(sequence[i:i+k])] += 1\n",
    "    return counter\n",
    "\n",
    "def segment_sequence(sequence, max_n=5):\n",
    "    N = len(sequence)\n",
    "    sequence = tuple(sequence)\n",
    "    ngram_count = count_ngrams(sequence, max_n=max_n)\n",
    "    u_arr = np.zeros(N - 1)\n",
    "    for k in range(0, N - 1):\n",
    "        u_k = 0\n",
    "        for n in range(2, min(max_n, k, N-k)):\n",
    "            s_1, s_2 = ngram_count[sequence[k-n+1:k+1]], ngram_count[sequence[k+1:k+n+1]]\n",
    "            u_k += np.mean([1 if s_1 >= ngram_count[sequence[k-n+i+1:k+i+1]] else 0 for i in range(1, n)])\n",
    "            u_k += np.mean([1 if s_2 >= ngram_count[sequence[k-n+i+1:k+i+1]] else 0 for i in range(1, n)])\n",
    "        u_arr[k] = u_k / max_n / 2\n",
    "    \n",
    "    sequence = list(sequence)\n",
    "    segments = []\n",
    "    prev_idx = 0\n",
    "    for idx in range(1, N-1):\n",
    "        if u_arr[idx-1] < u_arr[idx] and u_arr[idx+1] < u_arr[idx]:\n",
    "            segments.append(sequence[prev_idx:idx+1])\n",
    "            prev_idx = idx+1\n",
    "\n",
    "    segments.append(sequence[prev_idx:])\n",
    "    return segments\n",
    "\n",
    "segments = segment_sequence(sequence, max_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(map(tuple, segments)).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:100]\n",
    "27, 8, 26, 4, 10, 27, 8, 26, 4, 10, 27, 8, 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[3*10**4+1500:3*10**4+3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[10**5+1500:10**5+3000])\n",
    "# plt.plot(labels[250:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r\"(a+b+c+)+\", \"daaabbbccabc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(ord('A'), ord('Z'))] + [chr(i) for i in range(ord('a'), ord('z'))]\n",
    "labels_string = ''.join([chars[l] for l in labels])\n",
    "labels_string[280:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r\"(K+Q+M+d+b+)+\")\n",
    "spans = [match.span() for match in re.finditer(pat, labels_string)]\n",
    "span_lengths = [span[1] - span[0] for span in spans]\n",
    "spans[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r\"K+(?!Q*K+)\")\n",
    "fspans = [match.span() for match in re.finditer(pat, labels_string)]\n",
    "fspans = [(max(0, s[0]-30), s[1]+30) for s in fspans]\n",
    "fig, axes = plt.subplots(nrows=10, ncols=2, figsize=(18, 20))\n",
    "for i in range(10):    \n",
    "    for ipart, part in enumerate(landmarks_data.body_parts):\n",
    "        if part in ['forepawR', 'forePawL', 'hindpawR', 'hindpawL']:\n",
    "            axes[i][0].plot(coords[fspans[i][0]+15: fspans[i][1]+15,ipart,0], label=f\"{part}_x\")\n",
    "            axes[i][0].plot(coords[fspans[i][0]+15: fspans[i][1]+15,ipart,1], label=f\"{part}_y\")\n",
    "    axes[i][1].plot(labels[slice(*fspans[i])])\n",
    "    axes[i][0].legend(loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(re.findall(r\"K+(?!K*Q+)\", labels_string)))\n",
    "print(len(re.findall(r\"K+Q+(?!Q*M+)\", labels_string)))\n",
    "print(len(re.findall(r\"K+Q+M+(?!M*d+)\", labels_string)))\n",
    "print(len(re.findall(r\"K+Q+M+d+(?!d*b+)\", labels_string)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=50, ncols=2, figsize=(18, 200))\n",
    "for i in range(50):    \n",
    "    for ipart, part in enumerate(landmarks_data.body_parts):\n",
    "        if part in ['forepawR', 'forePawL', 'hindpawR', 'hindpawL']:\n",
    "            axes[i][0].plot(coords[spans[i][0]+15: spans[i][1]+15,ipart,0], label=f\"{part}_x\")\n",
    "            axes[i][0].plot(coords[spans[i][0]+15: spans[i][1]+15,ipart,1], label=f\"{part}_y\")\n",
    "    axes[i][1].plot(labels[slice(*spans[i])])\n",
    "    axes[i][0].legend(loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(set(labels))\n",
    "transition_matrix = np.zeros((n_clusters, n_clusters))\n",
    "for i in range(len(labels) - 1):\n",
    "    transition_matrix[labels[i], labels[i+1]] += 1.\n",
    "\n",
    "np.fill_diagonal(transition_matrix, val=0)\n",
    "\n",
    "transition_matrix /= transition_matrix.sum(axis=0, keepdims=True)\n",
    "plt.imshow(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(idx_arr):\n",
    "    to_split = np.where(np.abs(np.diff(idx_arr)) > 1)[0] + 1\n",
    "    return np.split(idx_arr, indices_or_sections=to_split)\n",
    "behaviors = [split(np.where(y_gold==lbl)[0]) for lbl in set(y_gold)]\n",
    "sections = [np.stack([np.mean(X_encoded[sec], axis=0) for sec in beh]) for beh in behaviors]\n",
    "sections[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from torch import nn \n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import signal as sig\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from torch.utils import data\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataloader import LandmarkDataset, SequenceDataset, LandmarkWaveletDataset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import normalized_mutual_info_score, confusion_matrix, accuracy_score\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find landmark files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory of data\n",
    "# data_root = Path(\"/home/orel/Storage/Data/K6/\")\n",
    "# landmark_files = []\n",
    "\n",
    "# for subdir in os.listdir(data_root):\n",
    "#     for file in os.listdir(data_root/subdir/'Down'):\n",
    "#         if re.match(r\"00\\d*DeepCut_resnet50_Down2May25shuffle1_1030000\\.h5\", file):\n",
    "#             lfile = data_root/subdir/'Down'/file\n",
    "#             landmark_files.append(lfile)\n",
    "\n",
    "data_root = Path(\"/mnt/storage2/shuki/data/THEMIS\")\n",
    "\n",
    "landmark_files = [data_root / 'landmarks' / f for f in os.listdir(data_root / 'landmarks')]\n",
    "landmark_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the autoencoder\n",
    "\n",
    "create and train autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_autoencoder import Autoencoder, PLAutoencoder\n",
    "seqlen = 30\n",
    "model = PLAutoencoder(landmark_files, n_neurons=[2*12*(seqlen-1), 1024, 512, 30], lr=5e-4, seqlen=seqlen, patience=20, diff=True)\n",
    "# model.prepare_data()\n",
    "# model.load_state_dict(torch.load('models/11_03/model.pt'))\n",
    "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=10, max_epochs=60, logger=pl.loggers.WandbLogger(\"diff landmarks autoencoder\"))\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('models/11_03/model.pt')\n",
    "# model.load_state_dict(torch.load('models/11_03/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('models/01_13_diff')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), model_dir / 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the original and reconstructed data, each plot for a different feature / coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(x, y):\n",
    "    x = x.reshape(-1, 24)\n",
    "    y = y.reshape(-1, 24)\n",
    "    fig, axes = plt.subplots(ncols=4, nrows=6, figsize=(18, 18))\n",
    "    for i in range(6):\n",
    "        for j in range(4):\n",
    "            idx = 4*i + j\n",
    "            axes[i][j].plot(x[:,idx], label='orig')\n",
    "            axes[i][j].plot(y[:,idx], label='recon')\n",
    "            axes[i][j].set_title(f\"{idx}\")\n",
    "            axes[i][j].set_ylim(-3, 3)\n",
    "    plt.legend()\n",
    " \n",
    "with torch.no_grad():\n",
    "    bx = next(iter(model.train_dataloader()))\n",
    "    out = model(bx)\n",
    "compare_plot(bx[19].cpu().numpy(), out[19].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot(bx[2].cpu().numpy(), out[2].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the landmark coordinates from all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_datasets = []\n",
    "for file in landmark_files:\n",
    "    try:\n",
    "        ds = LandmarkDataset(file)\n",
    "        landmark_datasets.append(ds)\n",
    "        break\n",
    "    except OSError:\n",
    "        pass\n",
    "# coords = [sig.decimate(ds.coords, q=4, axis=0).astype(np.float32) for ds in landmark_datasets]\n",
    "coords = model.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the dataset from all the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, n_coords, _ = coords[0].shape\n",
    "all_data = [crds.reshape(-1, n_coords*2) for crds in coords]\n",
    "data_lengths = [d.shape[0] - model.seqlen for d in all_data]\n",
    "video_change_idxs = np.cumsum(data_lengths)[:-1]\n",
    "all_data = [SequenceDataset(d, seqlen=model.seqlen, diff=model.diff, step=1) for d in all_data]\n",
    "all_data = ConcatDataset(all_data)\n",
    "X_encoded = model.model.encode(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(model_dir / 'kmeans.pkl', 'rb') as file:\n",
    "#     pickle.dump(kmeans, file)\n",
    "    kmeans = pickle.load(file)\n",
    "    \n",
    "with open(model_dir / 'kmeans.pkl', 'bb') as file:\n",
    "    pickle.dump(kmeans, file)\n",
    "#     kmeans = pickle.load(file)\n",
    "# labels = np.load('models/11_03/labels.np.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering the data and splitting into segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "X_encoded = model.model.encode(all_data)\n",
    "kmeans = KMeans(K)\n",
    "labels = kmeans.fit_predict(X_encoded)\n",
    "'''\n",
    "split the sequence of labels and returns the sequence of segments of the form:\n",
    "      [(label0, segment_start0, segment_length0), ...]\n",
    "for example:\n",
    "44422222227777  ->  [(4, 0, 3), (2, 7), (7, 4)]\n",
    "'''\n",
    "def split_labels(labels):\n",
    "    split_at = np.where(np.diff(labels) != 0)[0] + 1\n",
    "    sequence = [[seg[0], split_at[i-1]*4 + model.seqlen*2, len(seg)*4] \\\n",
    "                for i, seg in enumerate(np.split(labels, indices_or_sections=split_at))]\n",
    "    sequence[0][1] = model.seqlen*2\n",
    "    return sequence\n",
    "\n",
    "labels_dict = dict(zip(landmark_files, \n",
    "                        np.split(labels, indices_or_sections=video_change_idxs)))\n",
    "\n",
    "data_dict = dict(zip(landmark_files,\n",
    "                    np.split(all_data, indices_or_sections=video_change_idxs)))\n",
    "\n",
    "X_encoded_dict = dict(zip(landmark_files,\n",
    "                         np.split(X_encoded, indices_or_sections=video_change_idxs)))\n",
    "\n",
    "segment_dict = dict(zip(landmark_files, \n",
    "                        map(split_labels, np.split(labels, indices_or_sections=video_change_idxs))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(model_dir / 'kmeans.pkl', 'wb') as file:\n",
    "    pickle.dump(kmeans, file)\n",
    "np.save(model_dir / 'labels.np', labels)\n",
    "\n",
    "with open(model_dir / 'labels_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(labels_dict, file)\n",
    "    \n",
    "with open(model_dir / 'data_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(data_dict, file)\n",
    "    \n",
    "with open(model_dir / 'segments_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(segment_dict, file)\n",
    "    \n",
    "with open(model_dir / 'x_encoded_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(X_encoded_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count = Counter(labels)\n",
    "ratios = {idx: count[idx] / len(labels) for idx in set(labels)}\n",
    "q = 0.5\n",
    "proportions = {idx: ratios[idx]**q for idx in set(labels)}\n",
    "proportions = {idx: proportions[idx] / sum(p for p in proportions.values()) for idx in set(labels)}\n",
    "def sample_ids(n_samples=10000, proportions=proportions):\n",
    "    ids = []\n",
    "    for idx in set(labels):\n",
    "        cluster_ids = np.where(labels==idx)[0]\n",
    "        n_cluster_samples = int(n_samples * proportions[idx])\n",
    "        ids.append(np.random.choice(cluster_ids, size=n_cluster_samples, replace=False))\n",
    "    ids = np.concatenate(ids)\n",
    "    return ids\n",
    "\n",
    "sample_idxs = sample_ids()\n",
    "X_sample = X_encoded[sample_idxs]\n",
    "sample_labels = labels[sample_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE plot of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30)\n",
    "X_2d = tsne.fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "sample_labels = labels[sample_idxs]\n",
    "clusters = {int(i): X_2d[np.where(sample_labels==i)[0]] for i in range(30)}\n",
    "plt.figure(figsize=(10, 10))\n",
    "cluster_colors = cm.tab20.colors + cm.tab20b.colors + cm.tab20c.colors\n",
    "for idx, cluster in clusters.items():\n",
    "    # print(cluster)\n",
    "    plt.text(cluster.mean(0)[0], cluster.mean(0)[1], str(idx), fontsize=16)\n",
    "#     plt.annotate(str(idx), xy=cluster.mean(axis=0))\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], label=idx, s=1, color=cluster_colors[idx])\n",
    "    plt.legend(bbox_to_anchor=(1., 1.), prop={'size': 12}, markerscale=8)\n",
    "#     plt.savefig('plots/tsne.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some plots to show the cluster at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts_dict = dict(zip(landmark_datasets[0].body_parts, range(len(landmark_datasets[0]))))\n",
    "\n",
    "def plot_segments(axis, vid_file_idx, start_idx, end_idx, bparts):\n",
    "    bparts_idxs = [bodyparts_dict[bp] for bp in bparts]\n",
    "    plot_coords = coords[vid_file_idx][start_idx + model.seqlen//2: end_idx + model.seqlen//2, bparts_idxs]\n",
    "    duration = (end_idx - start_idx) * (1000 / 60)\n",
    "    for i, body_part in enumerate(bparts):\n",
    "        axis.plot(plot_coords[:,i,0], label=f\"{body_part}_x\")\n",
    "        axis.plot(plot_coords[:,i,1], label=f\"{body_part}_y\")\n",
    "    ymin, ymax = axis.get_ybound()\n",
    "    lbls = labels_dict[landmark_files[vid_file_idx]][start_idx: end_idx]\n",
    "#     label_dict = dict(zip(sorted(list(set(lbls))), range(len(set(lbls)))))\n",
    "    segment_edges = np.where(np.diff(lbls) != 0)[0]\n",
    "    segment_edges = np.append(0, segment_edges)\n",
    "    segment_edges = np.append(segment_edges, end_idx - start_idx - 1)\n",
    "    segment_labels = lbls[segment_edges]\n",
    "    axis.margins(0, 0)\n",
    "    axis.vlines(segment_edges, ymin=ymin, ymax=ymax, color='black', linestyle='dashed')\n",
    "    for i in range(1, len(segment_edges)):\n",
    "        cluster_color = cluster_colors[lbls[segment_edges[i]]]\n",
    "        axis.fill_betweenx([ymin, ymax], segment_edges[i-1], segment_edges[i], color=cluster_color, alpha=0.5)\n",
    "    color_patches = [mpatches.Patch(color=cluster_colors[i], label=f'cluster {i}', alpha=0.5) for i in set(lbls)]\n",
    "    cluster_color_legend = axis.legend(handles=color_patches, bbox_to_anchor=(1.0, 0.0), loc='lower left', title='clusters')\n",
    "    ax = plt.gca().add_artist(cluster_color_legend)\n",
    "    handles, labels = axis.get_legend_handles_labels()\n",
    "    axis.legend(handles, labels, bbox_to_anchor=(1.0, 1), title=\"body parts\")\n",
    "    axis.set_title(\"landmark coordinates timeseries\")\n",
    "    axis.set_xticks(np.arange(0, end_idx - start_idx, step=30))\n",
    "    axis.set_xticklabels(np.arange(0, duration/1000, step=0.5))\n",
    "    axis.set_xlabel(\"time [seconds]\")\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(18, 6))\n",
    "ax = plt.subplot().axes\n",
    "%pdb on\n",
    "plot_segments(ax, 6, 91600, 92100, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "# plt.savefig(\"plots/coords1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "ax = plt.subplot()\n",
    "plot_segments(ax, 6, 0, 300, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot()\n",
    "plot_segments(ax, 6, 0, 200, bparts=['forepawR', 'forePawL', 'hindpawR', 'hindpawL'])\n",
    "plt.savefig(\"plots/coords2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = labels_dict[landmark_files[6]]\n",
    "plt.plot(lbls[11800:16000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = labels_dict[landmark_files[6]]\n",
    "plt.plot(lbls[800:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some histogram plots of lengths of some of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "segments = split_labels(labels)\n",
    "segment_lengths = defaultdict(list)\n",
    "for seg in segments:\n",
    "    if seg[2] < 200:\n",
    "        segment_lengths[seg[0]].append(seg[2]/(4*60))\n",
    "    \n",
    "clusters_to_plot = [19, 23, 14, 10]\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(clusters_to_plot), figsize=(8, 12), sharex=True)\n",
    "for i, cl in enumerate(clusters_to_plot):\n",
    "    axes[i].hist(segment_lengths[cl], bins=20, density=True)\n",
    "    axes[i].set_xlim(0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save examples from cluster as frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import importlib\n",
    "import clip_videos\n",
    "from collections import defaultdict\n",
    "importlib.reload(clip_videos)\n",
    "\n",
    "def read_clip_as_frames(cap: cv.VideoCapture, start_idx, end_idx, df, fps=10):\n",
    "    frame_gen = clip_videos.extract_labeled_cut_frames(cap, start_idx, end_idx, df)\n",
    "    write_every = int(cap.get(cv.CAP_PROP_FPS) / fps)\n",
    "    frames = []\n",
    "    for i, frame in enumerate(frame_gen):\n",
    "        if i % write_every == 0:\n",
    "            frames.append(frame)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clips_as_frames(landmarks_file, cluster_segments, save_dir, min_seg_len=10, fps=20, n_samples=15):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    video_file = re.sub(r'DeepCut.*\\.h5', '.MP4', landmarks_file.name)\n",
    "    video_file = str(landmarks_file.parent / video_file)\n",
    "    assert os.path.exists(video_file)\n",
    "    vid_cap = cv.VideoCapture(video_file)\n",
    "    vid_cap.open(video_file)\n",
    "    cluster_frames = defaultdict(list)\n",
    "    for seg in cluster_segments:\n",
    "        if seg[2] >= min_seg_len:\n",
    "            cluster_frames[seg[0]].append((seg[1], seg[2]))\n",
    "    cluster_frames = {k: v for k, v in cluster_frames.items() if len(v) >= 15}\n",
    "    cluster_samples = {c: random.choices(cl, k=n_samples) for c, cl in cluster_frames.items()}\n",
    "    df = LandmarkDataset(landmarks_file).df\n",
    "    for cl_id,  cluster in cluster_samples.items():\n",
    "        print(cl_id)\n",
    "        if not os.path.exists(save_dir / f'{cl_id}'):\n",
    "            os.makedirs(save_dir / f'{cl_id}', exist_ok=True)\n",
    "        mid_frames = [c[0] for c in cluster]\n",
    "        n_frames = [c[1] for c in cluster]\n",
    "        n_frames = int(min(60, np.mean(n_frames) + np.std(n_frames)))\n",
    "        for i, mid_frame in enumerate(mid_frames):\n",
    "            start_idx, end_idx = mid_frame - n_frames//2, mid_frame + n_frames//2\n",
    "            frames = read_clip_as_frames(vid_cap, start_idx, end_idx, df=df, fps=fps)\n",
    "            img = Image.fromarray(np.concatenate(frames, axis=1))\n",
    "            img.save(save_dir / f'{cl_id}' / f\"{i}.jpg\")\n",
    "    vid_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_file = landmark_files[6]\n",
    "np.array(segment_dict[landmarks_file])[:,2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "landmarks_file = landmark_files[6]\n",
    "df = landmark_datasets[6].df\n",
    "# cluster_subset = [6, 15, 22, 7, 2, 12, 25]\n",
    "# segments = [seg for seg in segment_dict[landmarks_file] if seg[0] in cluster_subset]\n",
    "save_dir = Path(\"clusters/frames/nov_03_1/\")\n",
    "save_clips_as_frames(landmarks_file, segment_dict[landmarks_file], save_dir, n_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "importlib.reload(dataloader)\n",
    "\n",
    "class VideoCaptureWrapper(object):\n",
    "    def __init__(self, vid_file, *args, **kwargs):\n",
    "        self.vid_file = str(vid_file)\n",
    "        self.vid_stream = cv.VideoCapture(self.vid_file, *args, **kwargs)\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.vid_stream.open(self.vid_file)\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self.vid_stream.release()\n",
    "        \n",
    "    def __getattr__(self, att):\n",
    "        return self.vid_stream.__getattribute__(att)\n",
    "    \n",
    "    def set(self, *args):\n",
    "        return self.vid_stream.set(*args)\n",
    "    \n",
    "    def get(self, *args):\n",
    "        return self.vid_stream.get(*args)\n",
    "\n",
    "\n",
    "class Video(object):\n",
    "    def __init__(self, video_file):\n",
    "        self.video_file = str(video_file)\n",
    "        self.cap = VideoCaptureWrapper(self.video_file)\n",
    "        self.fps = int(np.round(self.cap.get(cv.CAP_PROP_FPS)))\n",
    "        self.shape = np.array((self.cap.get(cv.CAP_PROP_FRAME_HEIGHT), self.cap.get(cv.CAP_PROP_FRAME_WIDTH)), dtype=np.int)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    @property\n",
    "    def _shape(self):\n",
    "        return np.array((self.cap.get(cv.CAP_PROP_FRAME_HEIGHT), self.cap.get(cv.CAP_PROP_FRAME_WIDTH)), dtype=np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return self.get_slice(idx)\n",
    "        with self.cap:\n",
    "            self.cap.set(cv.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                return frame\n",
    "            else:\n",
    "                raise Exception(\"frame not found\")\n",
    "            \n",
    "    def get_slice(self, s):\n",
    "        frames = []\n",
    "        with self.cap as cap:\n",
    "            step = 1 if s.step is None else s.step\n",
    "            start = 0 if s.start is None else s.start\n",
    "            stop = len(self) if s.stop is None else s.stop\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, start)\n",
    "            for i in range(stop - start):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.cap.release()\n",
    "                    raise Exeption(\"frame not found\")\n",
    "                if i % step == 0:\n",
    "                    frames.append(frame)\n",
    "        return frames\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.cap.open(self.video_file)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            return frame\n",
    "        else:\n",
    "            self.cap.release()\n",
    "\n",
    "            \n",
    "def get_files(vid_dir):\n",
    "    for file in os.listdir(vid_dir):\n",
    "        if re.match(r'\\d*\\.MP4', file):\n",
    "            vid_file = vid_dir / file\n",
    "            vid_id = file[:4]\n",
    "            landmarks_file = vid_dir / f'{vid_id}DeepCut_resnet50_Down2May25shuffle1_1030000.h5'\n",
    "            return vid_file, landmarks_file\n",
    "        \n",
    "color_pallete = [(0,204,0),(255,255,0),(255,102,102),(255,102,178),(102,0,204),(0,0,204),(0,128,255),(51,255,255),(204,255,204),(153,153,0),(153,0,76),(76,0,153,),(160,160,160)]\n",
    "\n",
    "class LandmarksVideo(object):\n",
    "    color_pallete = [(0,204,0),(255,255,0),(255,102,102),(255,102,178),(102,0,204),(0,0,204),(0,128,255),(51,255,255),(204,255,204),(153,153,0),(153,0,76),(76,0,153,),(160,160,160)]\n",
    "    def __init__(self, vid_dir=data_root/'2020-03-23'/'Down'):\n",
    "        self.vid_dir = vid_dir\n",
    "        vid_file, landmarks_file = get_files(vid_dir)\n",
    "        self.video = Video(vid_file)\n",
    "        self.landmarks = dataloader.LandmarkDataset(landmarks_file, normalize=False)\n",
    "        self.normalized_landmarks = dataloader.LandmarkDataset(landmarks_file, normalize=True)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return self.get_slice(idx)\n",
    "        frame = self.video[idx]\n",
    "        landmarks = self.landmarks[idx]\n",
    "        min_xy, max_xy = landmarks.min(0) - 30, landmarks.max(0) + 30\n",
    "        min_xy, max_xy = np.clip(min_xy, 0, self.video.shape).astype(np.int), np.clip(max_xy, 0, self.video.shape).astype(np.int)\n",
    "        cut_frame = frame[min_xy[1]:max_xy[1], min_xy[0]:max_xy[0]].copy()\n",
    "        for j, part in enumerate(self.landmarks.body_parts):\n",
    "            x, y = landmarks[j].astype(np.int) - min_xy\n",
    "            cv.circle(cut_frame, (x, y), 5, self.color_pallete[j], -1)\n",
    "        return cut_frame\n",
    "    \n",
    "    def get_slice(self, s):\n",
    "        frames = np.stack(self.video[s], axis=0)\n",
    "        landmarks = self.landmarks[s]\n",
    "        min_xy, max_xy = landmarks.min((0, 1)) - 20, landmarks.max((0, 1)) + 20\n",
    "        min_xy, max_xy = np.clip(min_xy, 0, self.video.shape).astype(np.int), np.clip(max_xy, 0, self.video.shape).astype(np.int)\n",
    "        cut_frames = frames[:, min_xy[1]:max_xy[1], min_xy[0]:max_xy[0]].copy()\n",
    "        for i in range(len(landmarks)):\n",
    "            for j, part in enumerate(self.landmarks.body_parts):\n",
    "                x, y = landmarks[i, j].astype(np.int) - min_xy\n",
    "                cv.circle(cut_frames[i], (x, y), 5, self.color_pallete[j], -1)\n",
    "        return cut_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_file = landmark_files[6]\n",
    "video = LandmarksVideo(landmarks_file.parent)\n",
    "cluster_id = 3\n",
    "[seg for seg in segment_dict[landmarks_file] if seg[0]==cluster_id]\n",
    "seg = segment_dict[landmarks_file][304]\n",
    "try:\n",
    "    frames = video[seg[1]:seg[1] + seg[2]:12]\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('clips', exist_ok=True)\n",
    "for cluster_id, start, length in segment_dict[landmarks_file]:\n",
    "    os.makedirs(f'clips/{cluster_id}', exist_ok=True)\n",
    "    if length >= 12 * 3:\n",
    "        *frames, = video[start: start + length: 12]\n",
    "        concat = np.concatenate(frames, axis=1)\n",
    "        Image.fromarray(concat).save(f'clips/{cluster_id}/{start}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for landmark_file in landmark_files:\n",
    "    video = LandmarksVideo(landmark_file.parent)\n",
    "    os.makedirs('clusters/frames/11_10', exist_ok=True)\n",
    "    for cluster_id, start, length in segment_dict[landmark_file]:\n",
    "        os.makedirs(f'clusters/frames/11_10/{cluster_id}', exist_ok=True)\n",
    "        if length >= 12 * 3:\n",
    "            *frames, = video[start: start + length: 10]\n",
    "            concat = np.concatenate(frames, axis=1)\n",
    "            Image.fromarray(concat).save(f'clusters/frames/11_10/{cluster_id}/{start}.png')\n",
    "            concat = np.concatenate(frames, axis=0)\n",
    "            Image.fromarray(concat).save(f'clusters/frames/11_10/{cluster_id}/{start}_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = segment_dict[landmarks_file][304]\n",
    "try:\n",
    "    *frames, = video[seg[1]:seg[1] + seg[2]:12]\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.concatenate(frames, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving clips of clusters from the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import importlib\n",
    "import random\n",
    "import clip_videos\n",
    "from collections import defaultdict\n",
    "importlib.reload(clip_videos)\n",
    "\n",
    "# save clips for each cluster from a single video\n",
    "def save_clips(landmarks_file, cluster_segments, save_dir, min_seg_len=10):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    video_file = re.sub(r'DeepCut.*\\.h5', '.MP4', landmarks_file.name)\n",
    "    video_file = landmarks_file.parent / video_file\n",
    "    assert os.path.exists(video_file)\n",
    "    cluster_frames = defaultdict(list)\n",
    "    for seg in cluster_segments:\n",
    "        if seg[2] >= min_seg_len:\n",
    "            cluster_frames[seg[0]].append((seg[1] + seg[2]//2, seg[2]//2))\n",
    "    cluster_frames = {k: v for k, v in cluster_frames.items() if len(v) >= 15}\n",
    "    cluster_samples = {c: random.choices(cl, k=15) for c, cl in cluster_frames.items()}\n",
    "    df = LandmarkDataset(landmarks_file).df\n",
    "    for cl_id,  cluster in cluster_samples.items():\n",
    "        mid_frames = [c[0] for c in cluster]\n",
    "        n_frames = [c[1] for c in cluster]\n",
    "        n_frames = int(min(60, np.mean(n_frames) + np.std(n_frames)))\n",
    "        clip_videos.save_collage_with_labels_short(str(video_file), df, mid_frames, n_frames_around=n_frames,\n",
    "                                             save_file=f'{save_dir}/cluster_{cl_id}.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save clips from all videos, from each video in a seoperate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lfile, segments in segment_dict.items():\n",
    "    save_dir = f'clusters/sept15/{lfile.name[:4]}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        save_clips(lfile, segments, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not really important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "split_at = np.where(np.diff(labels) != 0)[0] + 1\n",
    "sequence = [[s[0], split_at[i-1], len(s)] for i, s in enumerate(np.split(labels, indices_or_sections=split_at))]\n",
    "sequence[0][1] = 0\n",
    "seg_lengths = defaultdict(list)\n",
    "for seg in sequence:\n",
    "    seg_lengths[seg[0]].append(seg[2])\n",
    "\n",
    "sequence = [seq for seq in sequence if seq[2] > 5]\n",
    "\n",
    "cluster_frames = defaultdict(list)\n",
    "for seq in sequence:\n",
    "    cluster_frames[seq[0]].append((seq[1]*4 + seq[2]*2, seq[2]*2))\n",
    "\n",
    "cluster_frames = {c:cl for c, cl in cluster_frames.items() if len(cl)>25}\n",
    "# len(cluster_frames)\n",
    "cluster_samples = {c: random.choices(cl, k=15) for c, cl in cluster_frames.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import importlib\n",
    "import clip_videos\n",
    "importlib.reload(clip_videos)\n",
    "\n",
    "video_file = data_root/'2020-03-23'/'Down'/'0008DeepCut_resnet50_Down2May25shuffle1_1030000_labeled.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl_id,  cluster in cluster_samples.items():\n",
    "    n_frames = [c[1] for c in cluster]\n",
    "    print(cl_id, np.mean(n_frames), np.std(n_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = LandmarkDataset(landmarks_file).df\n",
    "for cl_id,  cluster in cluster_samples.items():\n",
    "    mid_frames = [c[0] for c in cluster]\n",
    "    n_frames = [c[1] for c in cluster]\n",
    "    n_frames = int(min(60, np.mean(n_frames) + np.std(n_frames)))\n",
    "    print(mid_frames)\n",
    "    clip_videos.save_collage_with_labels_short(str(video_file), df, mid_frames, n_frames_around=n_frames,\n",
    "                                         save_file=f'clusters/example_1/cluster_{cl_id}.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls clusters/example_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = [seq[0] for seq in sequence]\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def count_ngrams(sequence, max_n=10):\n",
    "    N = len(sequence)\n",
    "    counter = defaultdict(int)\n",
    "    for k in range(1, max_n):\n",
    "        for i in range(N-k):\n",
    "            counter[tuple(sequence[i:i+k])] += 1\n",
    "    return counter\n",
    "\n",
    "def segment_sequence(sequence, max_n=5):\n",
    "    N = len(sequence)\n",
    "    sequence = tuple(sequence)\n",
    "    ngram_count = count_ngrams(sequence, max_n=max_n)\n",
    "    u_arr = np.zeros(N - 1)\n",
    "    for k in range(0, N - 1):\n",
    "        u_k = 0\n",
    "        for n in range(2, min(max_n, k, N-k)):\n",
    "            s_1, s_2 = ngram_count[sequence[k-n+1:k+1]], ngram_count[sequence[k+1:k+n+1]]\n",
    "            u_k += np.mean([1 if s_1 >= ngram_count[sequence[k-n+i+1:k+i+1]] else 0 for i in range(1, n)])\n",
    "            u_k += np.mean([1 if s_2 >= ngram_count[sequence[k-n+i+1:k+i+1]] else 0 for i in range(1, n)])\n",
    "        u_arr[k] = u_k / max_n / 2\n",
    "    \n",
    "    sequence = list(sequence)\n",
    "    segments = []\n",
    "    prev_idx = 0\n",
    "    for idx in range(1, N-1):\n",
    "        if u_arr[idx-1] < u_arr[idx] and u_arr[idx+1] < u_arr[idx]:\n",
    "            segments.append(sequence[prev_idx:idx+1])\n",
    "            prev_idx = idx+1\n",
    "\n",
    "    segments.append(sequence[prev_idx:])\n",
    "    return segments\n",
    "\n",
    "segments = segment_sequence(sequence, max_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(map(tuple, segments)).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:100]\n",
    "27, 8, 26, 4, 10, 27, 8, 26, 4, 10, 27, 8, 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[3*10**4+1500:3*10**4+3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[10**5+1500:10**5+3000])\n",
    "# plt.plot(labels[250:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r\"(a+b+c+)+\", \"daaabbbccabc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(ord('A'), ord('Z'))] + [chr(i) for i in range(ord('a'), ord('z'))]\n",
    "labels_string = ''.join([chars[l] for l in labels])\n",
    "labels_string[280:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r\"(K+Q+M+d+b+)+\")\n",
    "spans = [match.span() for match in re.finditer(pat, labels_string)]\n",
    "span_lengths = [span[1] - span[0] for span in spans]\n",
    "spans[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r\"K+(?!Q*K+)\")\n",
    "fspans = [match.span() for match in re.finditer(pat, labels_string)]\n",
    "fspans = [(max(0, s[0]-30), s[1]+30) for s in fspans]\n",
    "fig, axes = plt.subplots(nrows=10, ncols=2, figsize=(18, 20))\n",
    "for i in range(10):    \n",
    "    for ipart, part in enumerate(landmarks_data.body_parts):\n",
    "        if part in ['forepawR', 'forePawL', 'hindpawR', 'hindpawL']:\n",
    "            axes[i][0].plot(coords[fspans[i][0]+15: fspans[i][1]+15,ipart,0], label=f\"{part}_x\")\n",
    "            axes[i][0].plot(coords[fspans[i][0]+15: fspans[i][1]+15,ipart,1], label=f\"{part}_y\")\n",
    "    axes[i][1].plot(labels[slice(*fspans[i])])\n",
    "    axes[i][0].legend(loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(re.findall(r\"K+(?!K*Q+)\", labels_string)))\n",
    "print(len(re.findall(r\"K+Q+(?!Q*M+)\", labels_string)))\n",
    "print(len(re.findall(r\"K+Q+M+(?!M*d+)\", labels_string)))\n",
    "print(len(re.findall(r\"K+Q+M+d+(?!d*b+)\", labels_string)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=50, ncols=2, figsize=(18, 200))\n",
    "for i in range(50):    \n",
    "    for ipart, part in enumerate(landmarks_data.body_parts):\n",
    "        if part in ['forepawR', 'forePawL', 'hindpawR', 'hindpawL']:\n",
    "            axes[i][0].plot(coords[spans[i][0]+15: spans[i][1]+15,ipart,0], label=f\"{part}_x\")\n",
    "            axes[i][0].plot(coords[spans[i][0]+15: spans[i][1]+15,ipart,1], label=f\"{part}_y\")\n",
    "    axes[i][1].plot(labels[slice(*spans[i])])\n",
    "    axes[i][0].legend(loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(labels[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(set(labels))\n",
    "transition_matrix = np.zeros((n_clusters, n_clusters))\n",
    "for i in range(len(labels) - 1):\n",
    "    transition_matrix[labels[i], labels[i+1]] += 1.\n",
    "\n",
    "np.fill_diagonal(transition_matrix, val=0)\n",
    "\n",
    "transition_matrix /= transition_matrix.sum(axis=0, keepdims=True)\n",
    "plt.imshow(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(idx_arr):\n",
    "    to_split = np.where(np.abs(np.diff(idx_arr)) > 1)[0] + 1\n",
    "    return np.split(idx_arr, indices_or_sections=to_split)\n",
    "behaviors = [split(np.where(y_gold==lbl)[0]) for lbl in set(y_gold)]\n",
    "sections = [np.stack([np.mean(X_encoded[sec], axis=0) for sec in beh]) for beh in behaviors]\n",
    "sections[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
